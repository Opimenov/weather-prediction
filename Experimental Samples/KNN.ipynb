{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS670 Group Project Phase 3\n",
    "Team members:\n",
    "Alexander Burke Alexander.Burke001@umb.edu\n",
    "Divya Bajaj : Divya.Bajaj001@umb.edu\n",
    "Yu-Ju Chien : Yuju.Chien001@umb.edu\n",
    "Oleksandr Pimenov: pialgi@live.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12.66' '15.85' '279.88' '290.75']\n",
      " ['13.5' '-13.42' '279.48' '290.91']\n",
      " ['11.28' '8.75' '279.83' '291.23']\n",
      " ..., \n",
      " ['0.70001' '-1.88' '284.47' '288.55']\n",
      " ['5.12' '-2.23' '282.5' '289.02']\n",
      " ['7.7' '3.42' '282.4' '289.55']]\n",
      " \n",
      "[[ 0.0313305   0.039225    0.69263676  0.71953744]\n",
      " [ 0.03342772 -0.03322963  0.69202804  0.72033018]\n",
      " [ 0.0279116   0.02165128  0.69242044  0.72062897]\n",
      " ..., \n",
      " [ 0.00172756 -0.00463967  0.70204566  0.71211472]\n",
      " [ 0.01266729 -0.0055172   0.69892778  0.71505878]\n",
      " [ 0.01903354  0.00845386  0.69806118  0.71573518]]\n",
      "((9497L, 4L), (1803L, 4L))\n",
      "((9497L, 1L), (1803L, 1L))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Task 1: Split the experimental samples and normalize the samples\n",
    "data0 = np.load('data_selected_1980_2010.npy')\n",
    "data1 = np.load('target_1980_2010.npy')\n",
    "# Concatenate data_selected(features) with target\n",
    "data = np.concatenate((data0, data1), axis = 1)\n",
    "normalized_x = preprocessing.normalize(data0)\n",
    "print(data0)\n",
    "print(\" \")\n",
    "print(normalized_x)\n",
    "\n",
    "split = 9497\n",
    "x_train, x_test, y_train, y_test = normalized_x[:split, :], normalized_x[split:, :], data1[:split, 1:], data1[split:, 1:]\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Split the data to training set(first 9497 rows) and testing set(last 1803 rows)\n",
    "# split = 9497\n",
    "# train, test = data[:split, :], data[split:, :]\n",
    "# print(\"Training Set: \")\n",
    "# print(train)\n",
    "# print(train.shape)\n",
    "# print(\"Testing Set: \")\n",
    "# print(test)\n",
    "# print(test.shape)\n",
    "\n",
    "####################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1\n",
      "0.902939545202\n",
      "[[1613   71]\n",
      " [ 104   15]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.96      0.95      1684\n",
      "        1.0       0.17      0.13      0.15       119\n",
      "\n",
      "avg / total       0.89      0.90      0.90      1803\n",
      "\n",
      "K = 2\n",
      "0.931225734886\n",
      "[[1678    6]\n",
      " [ 118    1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.96      1684\n",
      "        1.0       0.14      0.01      0.02       119\n",
      "\n",
      "avg / total       0.88      0.93      0.90      1803\n",
      "\n",
      "K = 3\n",
      "0.929561841375\n",
      "[[1672   12]\n",
      " [ 115    4]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.99      0.96      1684\n",
      "        1.0       0.25      0.03      0.06       119\n",
      "\n",
      "avg / total       0.89      0.93      0.90      1803\n",
      "\n",
      "K = 4\n",
      "0.931225734886\n",
      "[[1679    5]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.96      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 5\n",
      "0.930671103716\n",
      "[[1677    7]\n",
      " [ 118    1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.96      1684\n",
      "        1.0       0.12      0.01      0.02       119\n",
      "\n",
      "avg / total       0.88      0.93      0.90      1803\n",
      "\n",
      "K = 6\n",
      "0.932889628397\n",
      "[[1682    2]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 7\n",
      "0.932334997227\n",
      "[[1681    3]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.96      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 8\n",
      "0.932889628397\n",
      "[[1682    2]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 9\n",
      "0.932889628397\n",
      "[[1682    2]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 10\n",
      "0.933444259567\n",
      "[[1683    1]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 11\n",
      "0.933444259567\n",
      "[[1683    1]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 12\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 13\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 14\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 15\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 16\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 17\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 18\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 19\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 20\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 21\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 22\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 23\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 24\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 25\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 26\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 27\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 28\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "K = 29\n",
      "0.933998890738\n",
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n",
      "[0.90293954520244035, 0.93122573488630056, 0.92956184137548525, 0.93122573488630056, 0.93067110371602879, 0.93288962839711587, 0.9323349972268441, 0.93288962839711587, 0.93288962839711587, 0.93344425956738764, 0.93344425956738764, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594, 0.9339988907376594]\n",
      "max = 0.933999\n",
      "k = 12\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest-Neighbors Classifer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = []\n",
    "range = np.arange(1, 30)\n",
    "max = -1\n",
    "k = 0\n",
    "for n in range:\n",
    "    print \"K = %d\" % n\n",
    "    knn = KNeighborsClassifier(n_neighbors = n)\n",
    "    knn.fit(x_train, y_train.ravel())\n",
    "    y_pred = knn.predict(x_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    if (max < metrics.accuracy_score(y_test, y_pred)):\n",
    "        max = metrics.accuracy_score(y_test, y_pred)\n",
    "        k = n\n",
    "print(accuracy)\n",
    "print \"max_accuracy = %f\" % max \n",
    "print \"k = %d\" % k\n",
    "\n",
    "# We get better accuracy after k reaches 16 and the accuracy is 0.9339988907376594."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xd91d7f0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIR0Ch21Q0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9f7bcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "%matplotlib inline\n",
    "\n",
    "plot.plot(range, accuracy)\n",
    "plot.xlabel('Number of Neighbors k')\n",
    "plot.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1684    0]\n",
      " [ 119    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.97      1684\n",
      "        1.0       0.00      0.00      0.00       119\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now is the time to evaluate how we did\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#y_score = knn.fit(x_train, y_train.ravel()).decision_function(x_test)\n",
    "#print(y_score)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "#for i in range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score = 0.500000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ROC_AUC_Score: Computing the area under the ROC-curve\n",
    "ras = roc_auc_score(y_test, y_pred)\n",
    "print \"roc_auc_score = %f\" % ras\n",
    "\n",
    "\n",
    "\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(x_test, y_pred, pos_label = 2)\n",
    "# print(fpr)\n",
    "# print(tpr)\n",
    "# print(thresholds)\n",
    "# print(\" \")\n",
    "# print(y_pred)\n",
    "# auc = metrics.auc(fpr, tpr)\n",
    "# print(auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
